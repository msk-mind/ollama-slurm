# Qwen3 30B - P40 Profile
# P40: 24GB VRAM, max 1 per node
# Model: ~18GB on 1 GPU
# KV cache at 16K: ~3.25GB
# Total VRAM: ~21.25GB -> fits on P40 24GB
MODEL_FILE="~/.cache/llama.cpp/unsloth_Qwen3-30B-A3B-Instruct-2507-GGUF_Qwen3-30B-A3B-Instruct-2507-Q4_K_M.gguf"
CPUS=8
MEM="32G"
GPUS=1
GPU_TYPE="p40"
CONTEXT_SIZE=16384
N_GPU_LAYERS=-1
EXTRA_ARGS=""
